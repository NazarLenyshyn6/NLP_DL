{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Protocol\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Introducing Interface of text preprocessor\n",
    "class TextPreprocessorI(Protocol):\n",
    "    @staticmethod\n",
    "    def preprocess(text: str) -> list[str]:\n",
    "        ...\n",
    "        \n",
    "        \n",
    "# Inplementation of concrete text preprocessor\n",
    "class TextPreprocessor:\n",
    "    @staticmethod\n",
    "    def preprocess(text: str) -> list[str]:\n",
    "        return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"The dog barks.\",\n",
    "    \"The cat meows.\",\n",
    "    \"The dog and cat are friends.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 1, 1, 0, 1, 1, 1]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BOW:\n",
    "    def __init__(self, preprocessor: TextPreprocessorI = TextPreprocessor):\n",
    "        self.preprocessor = preprocessor\n",
    "        \n",
    "        \n",
    "    def fit(self, corpus: list[str]) -> None:\n",
    "        self.vocab = {}\n",
    "        self.inverse_vocab = {}\n",
    "        word_idx = 0\n",
    "        \n",
    "        for text in corpus:\n",
    "            for token in self.preprocessor.preprocess(text): \n",
    "                if not token in self.vocab:\n",
    "                    self.vocab[token] = word_idx\n",
    "                    self.inverse_vocab[word_idx] = token\n",
    "                    word_idx += 1\n",
    "                    \n",
    "        \n",
    "    def transform(self, text: str) -> list[int]:\n",
    "        transformed_text = [0] * len(self.vocab)\n",
    "        preprocessed_text = self.preprocessor.preprocess(text)\n",
    "        \n",
    "        for token in preprocessed_text:\n",
    "            if token in self.vocab: transformed_text[self.vocab[token]] += 1\n",
    "                \n",
    "        return transformed_text\n",
    "        \n",
    "        \n",
    "    def fit_transform(self, corpus: list[str]) -> list[list[int]]:\n",
    "        self.fit(corpus)\n",
    "        \n",
    "        transformed_corputs = []\n",
    "        for text in corpus:\n",
    "            transformed_corputs.append(self.transform(text))\n",
    "            \n",
    "        return transformed_corputs\n",
    "\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return f'BOW(preprocessor={self.preprocessor})'\n",
    "    \n",
    "    \n",
    "bow_model = BOW()\n",
    "bow_model.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NGramBOW(BOW):\n",
    "    def __init__(self, n: int = 2, preprocessor: TextPreprocessorI = TextPreprocessor):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.n = n\n",
    "        \n",
    "    def _build_n_grams(self, text: list[str]) -> None:\n",
    "        left_pointer = 0\n",
    "        right_pointer = self.n - 1\n",
    "        \n",
    "        while right_pointer < len(text):\n",
    "            n_gram = tuple(text[left_pointer: right_pointer + 1])\n",
    "            if not n_gram in self.vocab: \n",
    "                self.vocab[n_gram] = self._word_idx\n",
    "                self.inverse_vocab[self._word_idx] = n_gram\n",
    "                self._word_idx += 1\n",
    "                \n",
    "            left_pointer += 1\n",
    "            right_pointer += 1\n",
    "        \n",
    "    def fit(self, corpus: list[str]) -> None:\n",
    "        self.vocab = {}\n",
    "        self.inverse_vocab = {}\n",
    "        self._word_idx = 0\n",
    "        \n",
    "        for text in corpus:\n",
    "            self._build_n_grams(self.preprocessor.preprocess(text))\n",
    "        \n",
    "    def transform(self, text: str) -> list[int]:\n",
    "        transformed_text = [0] * len(self.vocab)\n",
    "        preprocessed_text = self.preprocessor.preprocess(text)\n",
    "        \n",
    "        left_pointer, right_pointer = 0, self.n - 1\n",
    "        \n",
    "        while right_pointer < len(preprocessed_text):\n",
    "            n_gram = tuple(preprocessed_text[left_pointer: right_pointer + 1])\n",
    "            \n",
    "            if n_gram in self.vocab: \n",
    "                transformed_text[self.vocab[n_gram]] += 1\n",
    "                \n",
    "            right_pointer += 1\n",
    "            left_pointer += 1\n",
    "            \n",
    "        return transformed_text\n",
    "            \n",
    "\n",
    "    def __repr__(self)  -> str:\n",
    "        return f'NGramBOW(n={self.n}, preprocessor={self.preprocessor})'\n",
    "    \n",
    "model = NGramBOW(n=2)\n",
    "model.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.754887502163468"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class PPMI:\n",
    "    def __init__(self, preprocessor: TextPreprocessorI = TextPreprocessor):\n",
    "        self.preprocessor = preprocessor\n",
    "        \n",
    "        \n",
    "    def _get_pairs(self, text: str, idx: int = 0):\n",
    "        if len(self._pair) == 1:\n",
    "            self.word_counts[self._pair[0]] += 1\n",
    "            \n",
    "        if len(self._pair) == 2:\n",
    "            self.co_occurrence[(self._pair[0], self._pair[1])] += 1\n",
    "            self.co_occurrence[(self._pair[1], self._pair[0])] += 1\n",
    "            return\n",
    "        \n",
    "        for word_idx in range(idx, len(text)):\n",
    "            self._pair.append(text[word_idx]) # step\n",
    "            self._get_pairs(text, word_idx + 1) # traverce step\n",
    "            self._pair.pop() # step back\n",
    "        \n",
    "        \n",
    "    def fit(self, corpus: list[str]) -> None:\n",
    "        self._pair = []\n",
    "        self.co_occurrence = defaultdict(int)\n",
    "        self.word_counts = defaultdict(int)\n",
    "        self.paragraphs = len(corpus)\n",
    "        \n",
    "        for text in corpus:\n",
    "            text = self.preprocessor.preprocess(text)\n",
    "            self._get_pairs(text)\n",
    "            \n",
    "        \n",
    "    def compute(self, word_1: str, word_2: str) -> int:\n",
    "        if not (word_1, word_2) in self.co_occurrence and not (word_2, word_1) in self.co_occurrence:\n",
    "            return 0\n",
    "        \n",
    "        elif (word_1, word_2) in self.co_occurrence:\n",
    "            numerator = self.co_occurrence[(word_1, word_2)] / self.paragraphs\n",
    "            \n",
    "        elif (word_2, word_1) in self.co_occurrence:\n",
    "            numerator = self.co_occurrence[(word_2, word_1)] / self.paragraphs\n",
    "            \n",
    "        denominator = (self.word_counts[word_1] * self.word_counts[word_1]) / len(self.word_counts) ** 2\n",
    "            \n",
    "        return max(math.log2(numerator / denominator), 0)\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return f'PPMI(preprocessor={self.preprocessor})'\n",
    "    \n",
    "model = PPMI()\n",
    "model.fit(corpus)\n",
    "model.compute('friends', 'are')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
